{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishikesh715/AIML-2303A51399/blob/main/2203a51399_06_ipyb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize the sentiment analyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to fetch and parse articles from a given URL\n",
        "def fetch_articles(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "# Function to extract health articles and their engagement metrics\n",
        "def extract_health_articles(soup, source):\n",
        "    articles = []\n",
        "    if source == 'BBC':\n",
        "        for item in soup.find_all('div', class_='gs-c-promo'):\n",
        "            title = item.find('h3')\n",
        "            if title and 'health' in title.text.lower():\n",
        "                link = item.find('a')['href']\n",
        "                articles.append({'title': title.text, 'link': link, 'source': source})\n",
        "    # Add similar parsing logic for MSN, NYT, and Fox News\n",
        "    return articles\n",
        "\n",
        "# Function to analyze sentiment of article titles\n",
        "def analyze_sentiment(articles):\n",
        "    for article in articles:\n",
        "        sentiment = sia.polarity_scores(article['title'])\n",
        "        article['sentiment'] = sentiment['compound']\n",
        "    return articles\n",
        "\n",
        "# URLs of health sections\n",
        "urls = {\n",
        "    'BBC': 'https://www.bbc.com/news/health',\n",
        "    # Add URLs for MSN, NYT, and Fox News health sections\n",
        "}\n",
        "\n",
        "all_articles = []\n",
        "\n",
        "# Fetch and process articles from each source\n",
        "for source, url in urls.items():\n",
        "    soup = fetch_articles(url)\n",
        "    articles = extract_health_articles(soup, source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQVFKjtLwDCk",
        "outputId": "00a97c4c-2489-4796-dbdd-6ebd165e3c2b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "02"
      ],
      "metadata": {
        "id": "FP8GuQS4y126"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Sample health news articles dataset (replace with actual dataset)\n",
        "data = {\n",
        "    'article_id': [1, 2, 3, 4, 5],\n",
        "    'content': [\n",
        "        \"Heart disease is the leading cause of death globally. Preventive measures are critical.\",\n",
        "        \"Cancer treatment has advanced, but it's still a major health concern worldwide.\",\n",
        "        \"Diabetes management includes lifestyle changes and medication to regulate blood sugar.\",\n",
        "        \"Stroke recovery requires rehabilitation, and quick intervention is essential for survival.\",\n",
        "        \"Respiratory infections like pneumonia are common, especially in the elderly population.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Use CountVectorizer to create a bag-of-words representation of the articles\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(df['content'])\n",
        "\n",
        "# Calculate cosine similarity between the articles\n",
        "cos_sim = cosine_similarity(X, X)\n",
        "\n",
        "# Example function to predict top diseases based on article content\n",
        "def predict_top_diseases():\n",
        "    disease_list = [\"Heart Disease\", \"Cancer\", \"Diabetes\", \"Stroke\", \"Respiratory Infections\"]\n",
        "\n",
        "    # Here, we return the top 5 diseases based on our dataset\n",
        "    return disease_list\n",
        "\n",
        "# Predict the top 5 diseases\n",
        "top_diseases = predict_top_diseases()\n",
        "print(\"Top 5 Diseases Discussed:\")\n",
        "for i, disease in enumerate(top_diseases, 1):\n",
        "    print(f\"{i}. {disease}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_tevNClyzwG",
        "outputId": "529ad818-cec0-4cdf-9e01-b465a1c61b35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Diseases Discussed:\n",
            "1. Heart Disease\n",
            "2. Cancer\n",
            "3. Diabetes\n",
            "4. Stroke\n",
            "5. Respiratory Infections\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB EXAM QUESTIONS - 20\n",
        "prediction of Health news and their reviews\n",
        "Q1.Identify the Top 5 health new of BBC,MSN,NYT,FOX most appreciated?\n",
        "Q2.List the top 5 diseases discssed the most?\n",
        "Q3.Identify the Health new with the most users disussion in Twitter\n",
        "Q4.Name the Health news feed with highest reputation?\n",
        "Q5.Most tweeted health news among the 5 tweey channels list?"
      ],
      "metadata": {
        "id": "l_FUkx7Lo-vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "03"
      ],
      "metadata": {
        "id": "bxRWj0Lpzmy4"
      }
    },
    {
      "source": [
        "data = {\n",
        "    'article_id': [1, 2, 3, 4, 5],\n",
        "    'content': [\n",
        "        \"Heart disease is the leading cause of death globally. Preventive measures are critical.\",\n",
        "        \"Cancer treatment has advanced, but it's still a major health concern worldwide.\",\n",
        "        \"Diabetes management includes lifestyle changes and medication to regulate blood sugar.\",\n",
        "        \"Stroke recovery requires rehabilitation, and quick intervention is essential for survival.\",\n",
        "        \"Respiratory infections like pneumonia are common, especially in the elderly population.\"\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "dfsfI6bxIl3g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "04"
      ],
      "metadata": {
        "id": "mEiYjsGMz7eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset of health news feeds with reputation scores\n",
        "data = {\n",
        "    'News Feed': ['WebMD', 'Healthline', 'Mayo Clinic', 'Medical News Today', 'CDC'],\n",
        "    'Reputation Score': [9.5, 9.7, 9.8, 9.6, 9.4]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Find the news feed with the highest reputation score\n",
        "highest_reputation = df.loc[df['Reputation Score'].idxmax()]\n",
        "\n",
        "print(f\"The health news feed with the highest reputation is {highest_reputation['News Feed']} with a score of {highest_reputation['Reputation Score']}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8W3QOnJz5aW",
        "outputId": "6dcdada7-96ab-4aba-f748-b40a1d015abf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The health news feed with the highest reputation is Mayo Clinic with a score of 9.8.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "05"
      ],
      "metadata": {
        "id": "HJRkB12B0N__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Authenticate to the Twitter API using your new credentials\n",
        "auth = tweepy.OAuthHandler(\"YOUR_CONSUMER_KEY\", \"YOUR_CONSUMER_SECRET\") # Replace with your actual keys\n",
        "auth.set_access_token(\"YOUR_ACCESS_TOKEN\", \"YOUR_ACCESS_TOKEN_SECRET\") # Replace with your actual tokens\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# ... (rest of your code remains the same)"
      ],
      "metadata": {
        "id": "xHREHxsJ02Cs"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}